{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_using_sklearn():\n",
    "\n",
    "    df = pd.read_csv(\"test_scores.csv\")\n",
    "    r = LinearRegression()\n",
    "    r.fit(df[['math']],df.cs)\n",
    "    return r.coef_, r.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y):\n",
    "    m_curr = 0\n",
    "    b_curr = 0\n",
    "    iterations = 1000000\n",
    "    n = len(x)\n",
    "    learning_rate = 0.00002\n",
    "\n",
    "    cost_previous = float('inf')  # Start with a very large cost\n",
    "\n",
    "    for i in range(iterations):\n",
    "        y_predicted = m_curr * x + b_curr  # Predicted values\n",
    "        cost = (1/n) * sum((y - y_predicted) ** 2)  # Mean Squared Error\n",
    "\n",
    "        # Compute gradients\n",
    "        m_derivative = -(2/n) * sum(x * (y - y_predicted))\n",
    "        b_derivative = -(2/n) * sum(y - y_predicted)\n",
    "\n",
    "        # Update the coefficients\n",
    "        m_curr = m_curr - learning_rate * m_derivative\n",
    "        b_curr = b_curr - learning_rate * b_derivative\n",
    "\n",
    "        # Check for convergence\n",
    "        if math.isclose(cost, cost_previous, rel_tol=1e-20):\n",
    "            print(f\"Convergence reached at iteration {i}\")\n",
    "            break\n",
    "\n",
    "        cost_previous = cost  # Update cost for the next iteration\n",
    "\n",
    "        # Optionally print progress\n",
    "        if i % 10000 == 0:\n",
    "            print(f\"Iteration {i}: m={m_curr}, b={b_curr}, cost={cost}\")\n",
    "\n",
    "    return m_curr, b_curr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"test_scores.csv\")\n",
    "    x = np.array(df.math)\n",
    "    y = np.array(df.cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: m=0.19783600000000004, b=0.0027960000000000003, cost=5199.1\n",
      "Iteration 10000: m=1.0439449243951966, b=0.05787772678836625, cost=31.802546738173614\n",
      "Iteration 20000: m=1.0433500834378717, b=0.1000325613891773, cost=31.793659397661415\n",
      "Iteration 30000: m=1.0427687431862764, b=0.14123063601908342, cost=31.78517089907105\n",
      "Iteration 40000: m=1.0422005972239592, b=0.18149366561660926, cost=31.77706334336078\n",
      "Iteration 50000: m=1.0416453460889978, b=0.22084287227090682, cost=31.76931963475377\n",
      "Iteration 60000: m=1.0411026971161552, b=0.25929899640761717, cost=31.76192344468944\n",
      "Iteration 70000: m=1.040572364282621, b=0.2968823077208704, cost=31.754859177392703\n",
      "Iteration 80000: m=1.0400540680572523, b=0.33361261585717256, cost=31.748111936988433\n",
      "Iteration 90000: m=1.0395475352532375, b=0.3695092808567667, cost=31.741667496091658\n",
      "Iteration 100000: m=1.0390524988841021, b=0.4045912233580817, cost=31.73551226580732\n",
      "Iteration 110000: m=1.0385686980229838, b=0.4388769345705156, cost=31.729633267076466\n",
      "Iteration 120000: m=1.038095877665103, b=0.472384486020901, cost=31.724018103308254\n",
      "Iteration 130000: m=1.0376337885933522, b=0.5051315390787668, cost=31.718654934240377\n",
      "Iteration 140000: m=1.0371821872469362, b=0.5371353542654, cost=31.713532450972153\n",
      "Iteration 150000: m=1.036740835592997, b=0.5684128003516237, cost=31.708639852118537\n",
      "Iteration 160000: m=1.0363095010011474, b=0.5989803632491045, cost=31.703966821034058\n",
      "Iteration 170000: m=1.0358879561208565, b=0.6288541546998365, cost=31.699503504058733\n",
      "Iteration 180000: m=1.0354759787616161, b=0.6580499207684286, cost=31.695240489740645\n",
      "Iteration 190000: m=1.035073351775825, b=0.686583050141639, cost=31.69116878899054\n",
      "Iteration 200000: m=1.0346798629443374, b=0.7144685822395331, cost=31.687279816127415\n",
      "Iteration 210000: m=1.0342953048646022, b=0.7417212151425588, cost=31.683565370774335\n",
      "Iteration 220000: m=1.0339194748413436, b=0.768355313338705, cost=31.680017620567117\n",
      "Iteration 230000: m=1.033552174779726, b=0.7943849152948123, cost=31.676629084638833\n",
      "Iteration 240000: m=1.0331932110809383, b=0.8198237408560913, cost=31.673392617845238\n",
      "Iteration 250000: m=1.0328423945401517, b=0.8446851984776238, cost=31.67030139569873\n",
      "Iteration 260000: m=1.0324995402467927, b=0.8689823922917947, cost=31.66734889997774\n",
      "Iteration 270000: m=1.0321644674870785, b=0.8927281290152906, cost=31.66452890498245\n",
      "Iteration 280000: m=1.031836999648766, b=0.9159349246993638, cost=31.661835464407154\n",
      "Iteration 290000: m=1.031516964128061, b=0.9386150113268381, cost=31.659262898801547\n",
      "Iteration 300000: m=1.0312041922386426, b=0.9607803432594492, cost=31.656805783595203\n",
      "Iteration 310000: m=1.0308985191227493, b=0.9824426035388177, cost=31.654458937658905\n",
      "Iteration 320000: m=1.0305997836642857, b=1.0036132100444004, cost=31.652217412379798\n",
      "Iteration 330000: m=1.0303078284039002, b=1.0243033215117323, cost=31.650076481226588\n",
      "Iteration 340000: m=1.0300224994559906, b=1.044523843414005, cost=31.64803162978296\n",
      "Iteration 350000: m=1.0297436464275924, b=1.0642854337102121, cost=31.646078546228605\n",
      "Iteration 360000: m=1.02947112233911, b=1.0835985084628041, cost=31.644213112246916\n",
      "Iteration 370000: m=1.0292047835468443, b=1.1024732473278531, cost=31.642431394341283\n",
      "Iteration 380000: m=1.0289444896672806, b=1.1209195989206409, cost=31.64072963554071\n",
      "Iteration 390000: m=1.0286901035030958, b=1.1389472860593868, cost=31.639104247477782\n",
      "Iteration 400000: m=1.02844149097084, b=1.156565810890057, cost=31.637551802822134\n",
      "Iteration 410000: m=1.0281985210302673, b=1.173784459894762, cost=31.636069028053573\n",
      "Iteration 420000: m=1.0279610656152645, b=1.1906123087865526, cost=31.634652796559436\n",
      "Iteration 430000: m=1.0277289995663472, b=1.2070582272931918, cost=31.633300122041653\n",
      "Iteration 440000: m=1.0275022005646928, b=1.223130883832101, cost=31.632008152219903\n",
      "Iteration 450000: m=1.0272805490676673, b=1.23883875007951, cost=31.63077416281712\n",
      "Iteration 460000: m=1.0270639282458145, b=1.2541901054356779, cost=31.62959555181517\n",
      "Iteration 470000: m=1.0268522239212787, b=1.2691930413888726, cost=31.62846983396794\n",
      "Iteration 480000: m=1.0266453245076221, b=1.2838554657802954, cost=31.627394635561178\n",
      "Iteration 490000: m=1.0264431209510094, b=1.298185106972192, cost=31.626367689406973\n",
      "Iteration 500000: m=1.0262455066727267, b=1.3121895179213485, cost=31.625386830063224\n",
      "Iteration 510000: m=1.0260523775130057, b=1.3258760801601797, cost=31.62444998926754\n",
      "Iteration 520000: m=1.0258636316761227, b=1.3392520076873786, cost=31.623555191576102\n",
      "Iteration 530000: m=1.0256791696767433, b=1.3523243507703966, cost=31.622700550198058\n",
      "Iteration 540000: m=1.0254988942874839, b=1.3650999996614928, cost=31.621884263017133\n",
      "Iteration 550000: m=1.0253227104876668, b=1.3775856882294788, cost=31.621104608791512\n",
      "Iteration 560000: m=1.0251505254132336, b=1.3897879975090952, cost=31.620359943524562\n",
      "Iteration 570000: m=1.0249822483078, b=1.4017133591697215, cost=31.619648696998098\n",
      "Iteration 580000: m=1.0248177904748184, b=1.4133680589054707, cost=31.618969369461475\n",
      "Iteration 590000: m=1.0246570652308264, b=1.424758239748292, cost=31.61832052846917\n",
      "Iteration 600000: m=1.024499987859759, b=1.4358899053058625, cost=31.617700805860235\n",
      "Iteration 610000: m=1.0243464755682934, b=1.4467689229260035, cost=31.61710889487344\n",
      "Iteration 620000: m=1.0241964474422127, b=1.4574010267892696, cost=31.61654354739184\n",
      "Iteration 630000: m=1.024049824403755, b=1.46779182093137, cost=31.61600357131077\n",
      "Iteration 640000: m=1.0239065291699332, b=1.477946782196999, cost=31.615487828024413\n",
      "Iteration 650000: m=1.0237664862118006, b=1.4878712631265671, cost=31.614995230024665\n",
      "Iteration 660000: m=1.0236296217146392, b=1.4975704947774946, cost=31.614524738608186\n",
      "Iteration 670000: m=1.0234958635390554, b=1.5070495894813902, cost=31.61407536168602\n",
      "Iteration 680000: m=1.023365141182955, b=1.5163135435386736, cost=31.61364615169173\n",
      "Iteration 690000: m=1.023237385744381, b=1.5253672398521523, cost=31.613236203583366\n",
      "Iteration 700000: m=1.0231125298851993, b=1.5342154505006174, cost=31.612844652934964\n",
      "Iteration 710000: m=1.0229905077956039, b=1.542862839254205, cost=31.61247067411394\n",
      "Iteration 720000: m=1.022871255159429, b=1.5513139640326052, cost=31.61211347853996\n",
      "Iteration 730000: m=1.022754709120251, b=1.5595732793074526, cost=31.611772313022357\n",
      "Iteration 740000: m=1.0226408082482548, b=1.567645138450239, cost=31.611446458171713\n",
      "Iteration 750000: m=1.0225294925078579, b=1.5755337960268847, cost=31.61113522688305\n",
      "Iteration 760000: m=1.022420703226064, b=1.583243410040328, cost=31.61083796288694\n",
      "Iteration 770000: m=1.0223143830615393, b=1.5907780441220678, cost=31.610554039365837\n",
      "Iteration 780000: m=1.0222104759743869, b=1.5981416696741153, cost=31.610282857632054\n",
      "Iteration 790000: m=1.0221089271966102, b=1.6053381679622214, cost=31.610023845865637\n",
      "Iteration 800000: m=1.0220096832032457, b=1.6123713321616477, cost=31.609776457908414\n",
      "Iteration 810000: m=1.021912691684149, b=1.619244869356527, cost=31.609540172112574\n",
      "Iteration 820000: m=1.021817901516424, b=1.6259624024937707, cost=31.60931449024042\n",
      "Iteration 830000: m=1.0217252627374775, b=1.632527472292712, cost=31.609098936414085\n",
      "Iteration 840000: m=1.0216347265186836, b=1.6389435391113325, cost=31.608893056111825\n",
      "Iteration 850000: m=1.0215462451396458, b=1.6452139847702238, cost=31.608696415209707\n",
      "Iteration 860000: m=1.021459771963046, b=1.6513421143350662, cost=31.608508599066273\n",
      "Iteration 870000: m=1.021375261410063, b=1.657331157858657, cost=31.608329211648126\n",
      "Iteration 880000: m=1.021292668936346, b=1.663184272083456, cost=31.60815787469484\n",
      "Iteration 890000: m=1.021211951008538, b=1.6689045421054978, cost=31.607994226921438\n",
      "Iteration 900000: m=1.0211330650813293, b=1.6744949830004294, cost=31.60783792325645\n",
      "Iteration 910000: m=1.0210559695750332, b=1.6799585414127396, cost=31.60768863411445\n",
      "Iteration 920000: m=1.0209806238536685, b=1.6852980971089413, cost=31.607546044700918\n",
      "Iteration 930000: m=1.0209069882035409, b=1.6905164644954174, cost=31.60740985434855\n",
      "Iteration 940000: m=1.0208350238123127, b=1.6956163941018307, cost=31.607279775883303\n",
      "Iteration 950000: m=1.020764692748543, b=1.7006005740309462, cost=31.60715553501876\n",
      "Iteration 960000: m=1.0206959579416952, b=1.7054716313754426, cost=31.607036869777787\n",
      "Iteration 970000: m=1.0206287831625982, b=1.710232133602655, cost=31.60692352994011\n",
      "Iteration 980000: m=1.0205631330043494, b=1.714884589907846, cost=31.606815276514794\n",
      "Iteration 990000: m=1.0204989728636538, b=1.7194314525367393, cost=31.606711881236215\n",
      "Using gradient descent function: Coef 1.0204362751212823 Intercept 1.7238746787923669\n"
     ]
    }
   ],
   "source": [
    "m, b = gradient_descent(x,y)\n",
    "print(\"Using gradient descent function: Coef {} Intercept {}\".format(m, b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sklearn: Coef [1.01773624] Intercept 1.9152193111568891\n"
     ]
    }
   ],
   "source": [
    "m_sklearn, b_sklearn = predict_using_sklearn()\n",
    "print(\"Using sklearn: Coef {} Intercept {}\".format(m_sklearn,b_sklearn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
